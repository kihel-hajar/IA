 <img src="photo-kihel hajar.jpeg" style="height:464px;margin-right:432px"/>
 
<img src="NADA HOUMADI.jpg" style="height:464px;margin-right:432px"/>
# KIHEL HAJAR # NADA HOUMADI

**Numéro d’étudiant** : 24010389   /  24010393
**Classe** : CAC2

---


# RAPPORT ACADÉMIQUE

# Analyse Statistique, Gestion du Risque et Modélisation Prédictive

---

# Introduction Générale

Ce travail s’inscrit dans une démarche d’analyse quantitative appliquée à la finance et au risque bancaire.
L’objectif est triple :

1. Analyser le couple rendement/risque de deux portefeuilles financiers.
2. Mettre à jour une probabilité de défaut via le théorème de Bayes.
3. Construire un modèle prédictif de classification du risque de crédit à l’aide d’un algorithme K-Nearest Neighbors (KNN).

L’approche mobilise des outils de :

* Statistique descriptive
* Probabilités conditionnelles
* Théorie financière (VaR, Sharpe)
* Machine Learning supervisé

---

# PARTIE I — Analyse Financière et Mesure du Risque

## 1. Cadre Théorique

### 1.1 Rendement et Volatilité

Le rendement moyen mesure la performance attendue d’un actif.
La volatilité (écart-type) mesure la dispersion des rendements autour de leur moyenne et constitue un indicateur de risque.

La volatilité annuelle est obtenue par :

[
\sigma_{annuelle} = \sigma_{mensuelle} \times \sqrt{12}
]

Le rendement annuel est calculé par capitalisation :

[
R_{annuel} = (1 + R_{mensuel})^{12} - 1
]

---

### 1.2 Value at Risk (VaR)

La Value at Risk à 95% sous hypothèse de normalité est donnée par :

[
VaR = \mu + z_{\alpha} \sigma
]

où :

* ( \mu ) = rendement annuel moyen
* ( \sigma ) = volatilité annuelle
* ( z_{\alpha} ) = quantile de la loi normale

La VaR représente la perte maximale attendue avec un niveau de confiance de 95%.

---

### 1.3 Ratio de Sharpe

[
Sharpe = \frac{R_p - R_f}{\sigma_p}
]

Il mesure la performance ajustée du risque.

---

## 2. Analyse Empirique des Portefeuilles

Deux portefeuilles sont étudiés :

* Portefeuille A (Conservateur)
* Portefeuille B (Agressif)

### 2.1 Statistiques Descriptives

Le portefeuille A présente :

* Une moyenne modérée
* Une faible dispersion
* Une distribution relativement symétrique

Le portefeuille B présente :

* Une moyenne plus élevée
* Une volatilité nettement supérieure
* Une présence de valeurs extrêmes

L’analyse graphique (histogrammes et boxplots) confirme la différence structurelle de risque.

---

### 2.2 Analyse du Risque (VaR)

Les résultats montrent :

* Une VaR modérée pour le portefeuille A
* Une VaR significativement plus élevée pour le portefeuille B

Compte tenu d’un capital de 500 000 € et d’une perte maximale tolérée de 50 000 €, le portefeuille B peut dépasser la contrainte de risque.

---

### 2.3 Interprétation du Ratio de Sharpe

Le portefeuille A présente un ratio de Sharpe plus stable.
Le portefeuille B peut offrir un rendement supérieur, mais sa volatilité détériore sa performance ajustée du risque.

---

## Conclusion Partie I

Le portefeuille A apparaît plus adapté à un investisseur avers au risque.
Le portefeuille B convient uniquement à un profil spéculatif.

---

# PARTIE II — Théorème de Bayes et Gestion Dynamique du Risque

## 1. Fondement Théorique

Le théorème de Bayes permet de réviser une probabilité à la lumière d’une nouvelle information :

[
P(D|E) = \frac{P(E|D)P(D)}{P(E)}
]

Il constitue un outil fondamental en scoring crédit.

---

## 2. Application au Scoring Crédit

### 2.1 Situation Initiale

Segment Standard
Probabilité initiale de défaut : 5%

---

### 2.2 Mise à Jour avec Retard de Paiement

L’observation d’un retard augmente significativement la probabilité de défaut.

Interprétation :

* Le signal est fortement discriminant.
* La probabilité conditionnelle devient sensiblement supérieure au prior.

---

### 2.3 Mise à Jour Séquentielle

Après un deuxième événement (découvert bancaire important), la probabilité augmente encore.

Cette approche séquentielle illustre :

* La nature dynamique du risque
* L’importance des signaux comportementaux

---

## Conclusion Partie II

Le cadre bayésien permet :

* Une actualisation rationnelle du risque
* Une meilleure allocation des ressources de surveillance
* Une politique de crédit adaptative

---

# PARTIE III — Modélisation Prédictive par K-Nearest Neighbors

## 1. Présentation du Modèle

Le KNN est un algorithme de classification basé sur la distance.
Un individu est classé selon la majorité des K voisins les plus proches.

Caractéristiques :

* Méthode non paramétrique
* Sensible à la normalisation
* Dépend du choix du paramètre K

---

## 2. Construction du Dataset

Variables explicatives :

* Âge
* Revenu
* Dette
* Score interne

Variable cible :

* Défaut (0/1)

La probabilité de défaut est générée selon une fonction logistique dépendant du ratio dette/revenu et du score interne.

---

## 3. Prétraitement

* Division en échantillons d’apprentissage et de test
* Stratification pour préserver la proportion de défaut
* Standardisation des variables

La normalisation est essentielle car KNN repose sur la distance euclidienne.

---

## 4. Optimisation du Paramètre K

Une validation croisée 5-fold est réalisée.

La métrique retenue est l’AUC (Area Under the Curve) car :

* Les classes sont déséquilibrées
* L’AUC mesure la capacité de discrimination globale

Le meilleur K maximise l’AUC moyenne.

---

## 5. Interprétation des Résultats

Le modèle permet :

* Une discrimination correcte entre profils risqués et non risqués
* Une amélioration par rapport à une classification naïve

Limites :

* Sensibilité au bruit
* Difficulté d’interprétation économique
* Complexité en grande dimension

---

# Conclusion Générale

Ce travail illustre la complémentarité entre :

* Statistique descriptive
* Théorie financière
* Probabilités conditionnelles
* Machine Learning

Il met en évidence :

1. L’importance du compromis rendement/risque
2. La pertinence du cadre bayésien en gestion du crédit
3. La capacité des modèles supervisés à prédire le défaut

---

# Perspectives d’Amélioration

* Comparaison avec une régression logistique
* Introduction d’une matrice de coût asymétrique
* Test de robustesse hors échantillon
* Utilisation de méthodes plus avancées (Random Forest, XGBoost)

---
